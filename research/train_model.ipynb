{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import keras\n",
    "import yaml\n",
    "from keras import (\n",
    "    Sequential,\n",
    "    layers,\n",
    "    optimizers,\n",
    "    losses,\n",
    "    metrics,\n",
    "    callbacks,\n",
    "    regularizers,\n",
    ")\n",
    "from pathlib import Path\n",
    "from sklearn.metrics import ConfusionMatrixDisplay, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataTransformation:\n",
    "    def __init__(self, config: dict) -> None:\n",
    "        self.image_size = (\n",
    "            config[\"image_height\"],\n",
    "            config[\"image_width\"],\n",
    "        )\n",
    "        self.image_channels_expactation = config[\"image_channels_expectation\"]\n",
    "        self.class_names = []\n",
    "        self.batch_size = config[\"batch_size\"]\n",
    "\n",
    "    def get_dataset(self, path: Path) -> tuple[tf.data.Dataset]:\n",
    "\n",
    "        print(f\"Loading dataset from: {path}\")\n",
    "        train_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "            path / \"train\",\n",
    "            seed=242,\n",
    "            image_size=self.image_size,\n",
    "            batch_size=self.batch_size,\n",
    "            shuffle=True,\n",
    "            label_mode=\"categorical\",\n",
    "            color_mode=\"grayscale\" if self.image_channels_expactation == 1 else \"rgb\",\n",
    "            interpolation=\"gaussian\",\n",
    "            validation_split=0.1,\n",
    "            subset=\"training\",\n",
    "        )\n",
    "        val_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "            path / \"test\",\n",
    "            seed=242,\n",
    "            image_size=self.image_size,\n",
    "            batch_size=self.batch_size,\n",
    "            shuffle=True,\n",
    "            label_mode=\"categorical\",\n",
    "            color_mode=\"grayscale\" if self.image_channels_expactation == 1 else \"rgb\",\n",
    "            interpolation=\"gaussian\",\n",
    "            validation_split=0.1,\n",
    "            subset=\"validation\",\n",
    "        )\n",
    "        self.class_name = train_ds.class_names\n",
    "\n",
    "        for image, label in train_ds:\n",
    "            print(f\"Batched image shape: {image.shape}\")\n",
    "            print(f\"Batched label shape: {label.shape}\")\n",
    "            break\n",
    "\n",
    "        AUTOTUNE = tf.data.AUTOTUNE\n",
    "        train_ds = train_ds.cache().prefetch(buffer_size=AUTOTUNE)\n",
    "        val_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)\n",
    "        return train_ds, val_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    \"CNN\": {\n",
    "        \"input_shape\": [32, 32, 1],\n",
    "        \"num_classes\": 6,\n",
    "        \"conv_units\": [32, 64, 128, 512, 512],\n",
    "        \"dense_units\": [256, 512],\n",
    "        \"dropout_rate\": 0.25,\n",
    "        \"learning_rate\": 0.001,\n",
    "        \"l1\": 0.004,\n",
    "        \"l2\": 0.004,\n",
    "    },\n",
    "    \"MLP\": {\n",
    "        \"input_shape\": [32, 32, 1],\n",
    "        \"num_classes\": 6,\n",
    "        \"dense_units\": [128, 32],\n",
    "        \"dropout_rate\": 0.5,\n",
    "        \"learning_rate\": 0.001,\n",
    "        \"l1\": 0.004,\n",
    "        \"l2\": 0.004,\n",
    "    },\n",
    "    \"ViT\": {\n",
    "        \"input_shape\": [32, 32, 1],\n",
    "        \"num_classes\": 6,\n",
    "        \"dense_units\": [6],\n",
    "        \"dropout_rate\": 0.5,\n",
    "        \"learning_rate\": 0.001,\n",
    "        \"l1\": 0.004,\n",
    "        \"l2\": 0.004,\n",
    "    },\n",
    "    \"early_stopping\": {\"monitor\": \"val_loss\", \"patience\": 10},\n",
    "    \"reduce_lr\": {\n",
    "        \"monitor\": \"val_loss\",\n",
    "        \"patience\": 10,\n",
    "        \"factor\": 0.1,\n",
    "        \"min_lr\": 1e-06,\n",
    "    },\n",
    "}\n",
    "\n",
    "data_augmentation = Sequential(\n",
    "    [\n",
    "        layers.Rescaling(1.0 / 255),\n",
    "        layers.RandomFlip(\"horizontal\"),\n",
    "        layers.RandomRotation(0.1),\n",
    "        layers.RandomZoom(0.1),\n",
    "    ],\n",
    "    name=\"data_augmentation\",\n",
    ")\n",
    "\n",
    "\n",
    "early_stop = callbacks.EarlyStopping(\n",
    "    monitor=params[\"early_stopping\"][\"monitor\"],\n",
    "    patience=params[\"early_stopping\"][\"patience\"],\n",
    "    verbose=0,\n",
    "    mode=\"auto\",\n",
    ")\n",
    "\n",
    "reduce_lr = callbacks.ReduceLROnPlateau(\n",
    "    monitor=params[\"reduce_lr\"][\"monitor\"],\n",
    "    factor=params[\"reduce_lr\"][\"factor\"],\n",
    "    patience=params[\"reduce_lr\"][\"patience\"],\n",
    "    min_lr=params[\"reduce_lr\"][\"min_lr\"],\n",
    "    mode=\"auto\",\n",
    "    verbose=0,\n",
    ")\n",
    "\n",
    "\n",
    "def evaluate_model(model: keras.Sequential, test_ds: tf.data.Dataset):\n",
    "    result = model.evaluate(test_ds)\n",
    "    print(f\"Evaluating {model._name} model: {result}\")\n",
    "\n",
    "    y_pred = model.predict(test_ds)\n",
    "    y_pred = y_pred.argmax(axis=1)\n",
    "\n",
    "    y_true = test_ds.map(lambda x, y: y)\n",
    "    ConfusionMatrixDisplay(confusion_matrix(y_true, y_pred)).plot()\n",
    "    os.makedirs(name=f\"visualize/{model._name}\", exist_ok=True)\n",
    "    plt.savefig(f\"visualize/{model._name}/confusion_matrix.png\")\n",
    "    return result\n",
    "\n",
    "\n",
    "def fit_model(\n",
    "    model: keras.Sequential,\n",
    "    train_ds: tf.data.Dataset,\n",
    "    val_ds: tf.data.Dataset,\n",
    "    epochs: int = 10,\n",
    ") -> callbacks.History:\n",
    "    history = model.fit(\n",
    "        train_ds,\n",
    "        epochs=epochs,\n",
    "        validation_data=val_ds,\n",
    "        callbacks=[\n",
    "            early_stop,\n",
    "            reduce_lr,\n",
    "            callbacks.ModelCheckpoint(\n",
    "                filepath=f\"weights/{model._name}/best.keras\",\n",
    "                monitor=\"val_f1_score\",\n",
    "                save_best_only=True,\n",
    "                verbose=0,\n",
    "            ),\n",
    "            callbacks.ModelCheckpoint(\n",
    "                filepath=f\"weights/{model._name}/last.keras\",\n",
    "                monitor=\"val_loss\",\n",
    "                verbose=0,\n",
    "            ),\n",
    "            callbacks.CSVLogger(\"logs/\" + model._name + \".log\"),\n",
    "        ],\n",
    "    )\n",
    "    return history\n",
    "\n",
    "\n",
    "class CNN:\n",
    "    def __init__(self, params) -> None:\n",
    "        self.input_shape = params[\"input_shape\"]\n",
    "        self.num_classes = params[\"num_classes\"]\n",
    "        self.conv_units = params[\"conv_units\"]\n",
    "        self.dense_units = params[\"dense_units\"]\n",
    "        self.dropout_rate = params[\"dropout_rate\"]\n",
    "        self.initial_lr = params[\"learning_rate\"]\n",
    "        self.l1 = params[\"l1\"]\n",
    "        self.l2 = params[\"l2\"]\n",
    "\n",
    "    @property\n",
    "    def build_model(self) -> Sequential:\n",
    "        model = Sequential(\n",
    "            [layers.Input(self.input_shape), data_augmentation], name=\"CNN\"\n",
    "        )\n",
    "\n",
    "        for units in self.conv_units:\n",
    "            model.add(layers.Conv2D(units, 3, activation=\"relu\", padding=\"same\"))\n",
    "            model.add(layers.BatchNormalization())\n",
    "            model.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "            model.add(layers.Dropout(self.dropout_rate))\n",
    "\n",
    "        model.add(layers.Flatten())\n",
    "        for units in self.dense_units:\n",
    "            model.add(layers.Dense(units, activation=\"relu\"))\n",
    "            model.add(layers.Dropout(self.dropout_rate))\n",
    "\n",
    "        model.add(\n",
    "            layers.Dense(\n",
    "                self.num_classes,\n",
    "                activation=\"softmax\",\n",
    "                name=\"output\",\n",
    "            ),\n",
    "        )\n",
    "        model.compile(\n",
    "            optimizer=optimizers.Adam(learning_rate=self.initial_lr),\n",
    "            loss=losses.CategoricalCrossentropy(),\n",
    "            metrics=[\n",
    "                metrics.CategoricalAccuracy(),\n",
    "                metrics.AUC(),\n",
    "                metrics.Precision(),\n",
    "                metrics.Recall(),\n",
    "                metrics.F1Score(average=\"weighted\"),\n",
    "            ],\n",
    "        )\n",
    "        model._name = \"CNN\"\n",
    "        print(f\"{model._name} model summary: \")\n",
    "        print(model.summary())\n",
    "        os.makedirs(name=f\"visualize/{model._name}\", exist_ok=True)\n",
    "        keras.utils.plot_model(\n",
    "            model,\n",
    "            to_file=f\"visualize/{model._name}/layers_structure.png\",\n",
    "            show_shapes=True,\n",
    "            show_layer_names=True,\n",
    "        )\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    \"data_ingestion\": {\n",
    "        \"data_path\": \"dataset/\",\n",
    "    },\n",
    "    \"data_transformation\": {\n",
    "        \"image_width\": 32,\n",
    "        \"image_height\": 32,\n",
    "        \"image_channels_expectation\": 1,\n",
    "        \"batch_size\": 32,\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get dataset\n",
    "data_transformation = DataTransformation(config=config[\"data_transformation\"])\n",
    "train_ds, val_ds = data_transformation.get_dataset(\n",
    "    path=Path(config[\"data_ingestion\"][\"data_path\"]),\n",
    ")\n",
    "\n",
    "# Train model\n",
    "cnn = CNN(params=params[\"CNN\"]).build_model\n",
    "history = fit_model(model=cnn, train_ds=train_ds, val_ds=val_ds, epochs=10)\n",
    "\n",
    "# Show result of training\n",
    "for metric in history.history.keys():\n",
    "    if \"val\" in metric:\n",
    "        plt.scatter(\n",
    "            history.epoch,\n",
    "            history.history[metric],\n",
    "            label=metric,\n",
    "            color=\"orange\",\n",
    "        )\n",
    "    else:\n",
    "        plt.plot(\n",
    "            history.epoch,\n",
    "            history.history[metric],\n",
    "            label=metric,\n",
    "            color=\"blue\",\n",
    "        )\n",
    "    plt.legend()\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Value\")\n",
    "    plt.title(f\"{cnn._name}: {metric}\")\n",
    "    os.makedirs(name=f\"visualize/{cnn._name}\", exist_ok=True)\n",
    "    plt.savefig(f\"visualize/{cnn._name}/{metric}.png\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "emotion",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/huy/Workspace/PythonProject/DogEmotions-ImageClassification-TensorFlow\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "if Path.cwd().name != \"DogEmotions-ImageClassification-TensorFlow\":\n",
    "    ROOT = Path.cwd().parent\n",
    "    os.chdir(ROOT)\n",
    "    print(ROOT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-22 22:49:09.224140: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-04-22 22:49:09.264003: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-04-22 22:49:09.264044: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-04-22 22:49:09.265346: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-04-22 22:49:09.272062: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-04-22 22:49:09.272958: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-04-22 22:49:09.931910: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import cv2\n",
    "import src.logging as log\n",
    "import shutil\n",
    "\n",
    "from typing import Any, List, Tuple, Literal\n",
    "# from tqdm.autonotebook import tqdm, trange\n",
    "from tensorflow.python.data.ops.dataset_ops import DatasetV2\n",
    "# from collections import deque\n",
    "# from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/huy/Workspace/PythonProject/DogEmotions-ImageClassification-TensorFlow/Dataset/train/sad'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "demo = Path(ROOT / \"Dataset/train/sad/sad0.jpg\")\n",
    "str(demo.parent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "\n",
    "\n",
    "def get_label(path: Path) -> str:\n",
    "    return path.parent.name\n",
    "\n",
    "\n",
    "def one_hot_encode(label: str) -> int:\n",
    "    map_label = {\"angry\": 0, \"fear\": 1, \"happy\": 2, \"neutral\": 3, \"sad\": 4, \"surprise\": 5}\n",
    "    label = map_label[label]\n",
    "    return tf.one_hot(label, depth=6)\n",
    "\n",
    "\n",
    "def get_image(path: Path, img_size=(32, 32)) -> np.ndarray[float]:\n",
    "    img = cv2.imread(str(path))\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    img = cv2.resize(img, dsize=img_size, interpolation=cv2.INTER_LINEAR)\n",
    "    img = img.astype(np.float32) / 255.0\n",
    "    img = np.expand_dims(img, axis=-1)\n",
    "    return img\n",
    "\n",
    "\n",
    "def get_dataset(\n",
    "    path: Path,\n",
    "    img_size: Tuple[int, int] = (32, 32),\n",
    "    train_ratio: float = 0.8,\n",
    "    test_ratio: float = 0.1,\n",
    "    val_ratio: float = 0.1,\n",
    ") -> DatasetV2:\n",
    "\n",
    "    log.info(f\"Loading dataset from: {path}\")\n",
    "    list_labels = os.listdir(path)\n",
    "\n",
    "    list_images = []\n",
    "    try:\n",
    "        for label in list_labels:\n",
    "            label_dir = path / label\n",
    "            path_images = [\n",
    "                label_dir / f for f in os.listdir(label_dir) if f.endswith(\".jpg\")\n",
    "            ]\n",
    "            list_images.extend(path_images)\n",
    "        images = list(map(get_image, list_images))\n",
    "        labels = list(map(get_label, list_images))\n",
    "        labels = list(map(one_hot_encode, labels))\n",
    "    except Exception as e:\n",
    "        log.exception(e)\n",
    "\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((images, labels))\n",
    "    N = len(dataset)\n",
    "    dataset = dataset.shuffle(buffer_size=N + 1)\n",
    "\n",
    "    train_size = int(N * train_ratio)\n",
    "    test_size = int(N * test_ratio)\n",
    "    val_size = int(N * val_ratio)\n",
    "    train_ds = dataset.take(train_size)\n",
    "    test_ds = dataset.skip(train_size).take(test_size)\n",
    "    val_ds = dataset.skip(train_size + test_size).take(val_size)\n",
    "\n",
    "    return train_ds, val_ds, test_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-04-22 22:49:10.600\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.logging\u001b[0m:\u001b[36minfo\u001b[0m:\u001b[36m16\u001b[0m - \u001b[1mLoading dataset from: /home/huy/Workspace/PythonProject/DogEmotions-ImageClassification-TensorFlow/Dataset/emotion\u001b[0m\n",
      "2024-04-22 22:49:15.407443: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 144752640 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of train samples: 28272\n",
      "Number of val samples: 3534\n",
      "Number of test samples: 3534\n"
     ]
    }
   ],
   "source": [
    "train_ds, val_ds, test_ds = get_dataset(ROOT / \"Dataset/emotion\")\n",
    "\n",
    "print(f\"Number of train samples: {len(train_ds)}\")\n",
    "print(f\"Number of val samples: {len(val_ds)}\")\n",
    "print(f\"Number of test samples: {len(test_ds)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-22 22:49:44.511814: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 144752640 exceeds 10% of free system memory.\n",
      "2024-04-22 22:49:50.683861: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 144752640 exceeds 10% of free system memory.\n",
      "2024-04-22 22:49:51.556495: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 144752640 exceeds 10% of free system memory.\n"
     ]
    }
   ],
   "source": [
    "if os.path.exists(\"data_compression\"):\n",
    "    shutil.rmtree(\"data_compression\")\n",
    "\n",
    "train_ds.save(\"data_compression/train\", compression=\"GZIP\")\n",
    "val_ds.save(\"data_compression/val\", compression=\"GZIP\")\n",
    "test_ds.save(\"data_compression/test\", compression=\"GZIP\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(ds_path: Path) -> DatasetV2:\n",
    "    # with open(ds_path / \"element_spec\", \"rb\") as in_:\n",
    "    #     es = pickle.load(in_)\n",
    "    dataset = tf.data.Dataset.load(str(ds_path), compression=\"GZIP\")\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-04-22 22:49:52.461\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.logging\u001b[0m:\u001b[36minfo\u001b[0m:\u001b[36m16\u001b[0m - \u001b[1mNumber of train samples: 28272\u001b[0m\n",
      "\u001b[32m2024-04-22 22:49:52.462\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.logging\u001b[0m:\u001b[36minfo\u001b[0m:\u001b[36m16\u001b[0m - \u001b[1mNumber of val samples: 3534\u001b[0m\n",
      "\u001b[32m2024-04-22 22:49:52.463\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.logging\u001b[0m:\u001b[36minfo\u001b[0m:\u001b[36m16\u001b[0m - \u001b[1mNumber of test samples: 3534\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "train_ds = load_dataset(\"data_compression/train\")\n",
    "val_ds = load_dataset(\"data_compression/val\")\n",
    "test_ds = load_dataset(\"data_compression/test\")\n",
    "log.info(f\"Number of train samples: {len(train_ds)}\")\n",
    "log.info(f\"Number of val samples: {len(val_ds)}\")\n",
    "log.info(f\"Number of test samples: {len(test_ds)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "train_ds = train_ds.batch(batch_size=2**5).cache().prefetch(buffer_size=AUTOTUNE)\n",
    "val_ds = val_ds.batch(batch_size=2**5).cache().prefetch(buffer_size=AUTOTUNE)\n",
    "test_ds = test_ds.batch(batch_size=2**5).cache().prefetch(buffer_size=AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from keras import Sequential, Model\n",
    "from keras.layers import (\n",
    "    Dense,\n",
    "    Dropout,\n",
    "    Activation,\n",
    "    Flatten,\n",
    "    Input,\n",
    "    Conv2D,\n",
    "    MaxPooling2D,\n",
    "    BatchNormalization,\n",
    ")\n",
    "from keras.optimizers import SGD, Adam\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, LearningRateScheduler\n",
    "\n",
    "from keras.metrics import CategoricalAccuracy, Recall, Precision, F1Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CNN_model(img_height=32, img_width=32, initial_filter=2**5) -> Sequential:\n",
    "    model = Sequential()\n",
    "    model.add(Input(shape=(img_height, img_width, 1)))\n",
    "    # First\n",
    "    model.add(\n",
    "        Conv2D(\n",
    "            filters=initial_filter,\n",
    "            kernel_size=(3, 3),\n",
    "            activation=tf.nn.relu,\n",
    "        )\n",
    "    )\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    # Second\n",
    "    model.add(\n",
    "        Conv2D(filters=initial_filter * 2, kernel_size=(3, 3), activation=tf.nn.relu)\n",
    "    )\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    # Third\n",
    "    model.add(\n",
    "        Conv2D(filters=initial_filter * 2**2, kernel_size=(3, 3), activation=tf.nn.relu)\n",
    "    )\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128, activation=tf.nn.relu))\n",
    "    model.add(\n",
    "        Dense(\n",
    "            6,\n",
    "            activation=tf.nn.softmax,\n",
    "            kernel_regularizer=tf.keras.regularizers.l1(0.004),\n",
    "            activity_regularizer=tf.keras.regularizers.l2(0.004),\n",
    "        )\n",
    "    )\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=Adam(),\n",
    "        loss=\"categorical_crossentropy\",\n",
    "        metrics=[\n",
    "            CategoricalAccuracy(),\n",
    "            Precision(),\n",
    "            Recall(),\n",
    "            F1Score(average=\"weighted\"),\n",
    "        ],\n",
    "    )\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "def MLP_model() -> Sequential:\n",
    "    model = Sequential(\n",
    "        [\n",
    "            Input(shape=(32, 32, 1)),\n",
    "            Dense(128, activation=tf.nn.relu),\n",
    "            BatchNormalization(),\n",
    "            Dense(32, activation=tf.nn.relu),\n",
    "            BatchNormalization(),\n",
    "            Dropout(0.2),\n",
    "            Flatten(),\n",
    "            Dense(\n",
    "                6,\n",
    "                activation=\"softmax\",\n",
    "                kernel_regularizer=tf.keras.regularizers.l1(0.004),\n",
    "                activity_regularizer=tf.keras.regularizers.l2(0.004),\n",
    "            ),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=Adam(),\n",
    "        loss=\"categorical_crossentropy\",\n",
    "        metrics=[\n",
    "            keras.metrics.CategoricalAccuracy(name=\"categorical_accuracy\"),\n",
    "            keras.metrics.Precision(name=\"precision\"),\n",
    "            keras.metrics.Recall(name=\"recall\"),\n",
    "            F1Score(average=\"weighted\"),\n",
    "        ],\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 30, 30, 32)        320       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2  (None, 15, 15, 32)        0         \n",
      " D)                                                              \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 13, 13, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPoolin  (None, 6, 6, 64)          0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 4, 4, 128)         73856     \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPoolin  (None, 2, 2, 128)         0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 512)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 128)               65664     \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 6)                 774       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 159110 (621.52 KB)\n",
      "Trainable params: 159110 (621.52 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_2 (Dense)             (None, 32, 32, 128)       256       \n",
      "                                                                 \n",
      " batch_normalization (Batch  (None, 32, 32, 128)       512       \n",
      " Normalization)                                                  \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 32, 32, 32)        4128      \n",
      "                                                                 \n",
      " batch_normalization_1 (Bat  (None, 32, 32, 32)        128       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 32, 32, 32)        0         \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 32768)             0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 6)                 196614    \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 201638 (787.65 KB)\n",
      "Trainable params: 201318 (786.40 KB)\n",
      "Non-trainable params: 320 (1.25 KB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "cnn = CNN_model()\n",
    "mlp = MLP_model()\n",
    "cnn.summary()\n",
    "mlp.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn._name = \"cnn_model\"\n",
    "mlp._name = \"mlp_model\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_save_best_callbacks = ModelCheckpoint(\n",
    "    ROOT / \"weights\" / cnn.name / \"best.weights.h5\",\n",
    "    monitor=\"val_f1_score\",\n",
    "    save_best_only=True,\n",
    "    save_weights_only=True,\n",
    "    mode=\"max\",\n",
    ")\n",
    "\n",
    "f1_save_last_callbacks = ModelCheckpoint(\n",
    "    ROOT / \"weights\" / cnn.name / \"last.weights.h5\",\n",
    "    monitor=\"val_f1_score\",\n",
    "    save_weights_only=True,\n",
    "    mode=\"max\",\n",
    "    verbose=0,\n",
    ")\n",
    "\n",
    "f1_early_stopping_callback = EarlyStopping(\n",
    "    monitor=\"val_f1_score\", patience=3, mode=\"max\", restore_best_weights=True, verbose=1\n",
    ")\n",
    "\n",
    "\n",
    "def lr_scheduler(epoch):\n",
    "    k = 0.1\n",
    "    initial_lr = 1e-3\n",
    "    return initial_lr * np.exp(-k * epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "884/884 [==============================] - 12s 13ms/step - loss: 1.6926 - categorical_accuracy: 0.3261 - precision: 0.6505 - recall: 0.0552 - f1_score: 0.2664 - val_loss: 1.5296 - val_categorical_accuracy: 0.3834 - val_precision: 0.6961 - val_recall: 0.1562 - val_f1_score: 0.3199 - lr: 0.0010\n",
      "Epoch 2/10\n",
      "884/884 [==============================] - 11s 13ms/step - loss: 1.4690 - categorical_accuracy: 0.4270 - precision: 0.7287 - recall: 0.1700 - f1_score: 0.3955 - val_loss: 1.4166 - val_categorical_accuracy: 0.4522 - val_precision: 0.7924 - val_recall: 0.1653 - val_f1_score: 0.4331 - lr: 9.0484e-04\n",
      "Epoch 3/10\n",
      "884/884 [==============================] - 13s 15ms/step - loss: 1.3781 - categorical_accuracy: 0.4669 - precision: 0.7443 - recall: 0.2157 - f1_score: 0.4437 - val_loss: 1.3468 - val_categorical_accuracy: 0.4867 - val_precision: 0.7878 - val_recall: 0.1944 - val_f1_score: 0.4759 - lr: 8.1873e-04\n",
      "Epoch 4/10\n",
      "884/884 [==============================] - 11s 13ms/step - loss: 1.3175 - categorical_accuracy: 0.4937 - precision: 0.7524 - recall: 0.2512 - f1_score: 0.4751 - val_loss: 1.2877 - val_categorical_accuracy: 0.5082 - val_precision: 0.7900 - val_recall: 0.2363 - val_f1_score: 0.4985 - lr: 7.4082e-04\n",
      "Epoch 5/10\n",
      "884/884 [==============================] - 11s 13ms/step - loss: 1.2704 - categorical_accuracy: 0.5146 - precision: 0.7607 - recall: 0.2815 - f1_score: 0.4984 - val_loss: 1.2399 - val_categorical_accuracy: 0.5317 - val_precision: 0.7910 - val_recall: 0.2699 - val_f1_score: 0.5246 - lr: 6.7032e-04\n",
      "Epoch 6/10\n",
      "884/884 [==============================] - 13s 15ms/step - loss: 1.2293 - categorical_accuracy: 0.5348 - precision: 0.7656 - recall: 0.3078 - f1_score: 0.5210 - val_loss: 1.2031 - val_categorical_accuracy: 0.5492 - val_precision: 0.7927 - val_recall: 0.3019 - val_f1_score: 0.5439 - lr: 6.0653e-04\n",
      "Epoch 7/10\n",
      "884/884 [==============================] - 11s 13ms/step - loss: 1.1956 - categorical_accuracy: 0.5522 - precision: 0.7657 - recall: 0.3304 - f1_score: 0.5403 - val_loss: 1.1778 - val_categorical_accuracy: 0.5625 - val_precision: 0.7863 - val_recall: 0.3237 - val_f1_score: 0.5572 - lr: 5.4881e-04\n",
      "Epoch 8/10\n",
      "884/884 [==============================] - 13s 15ms/step - loss: 1.1651 - categorical_accuracy: 0.5673 - precision: 0.7685 - recall: 0.3512 - f1_score: 0.5565 - val_loss: 1.1556 - val_categorical_accuracy: 0.5696 - val_precision: 0.7750 - val_recall: 0.3509 - val_f1_score: 0.5648 - lr: 4.9659e-04\n",
      "Epoch 9/10\n",
      "884/884 [==============================] - 11s 13ms/step - loss: 1.1384 - categorical_accuracy: 0.5791 - precision: 0.7728 - recall: 0.3719 - f1_score: 0.5690 - val_loss: 1.1342 - val_categorical_accuracy: 0.5761 - val_precision: 0.7687 - val_recall: 0.3724 - val_f1_score: 0.5714 - lr: 4.4933e-04\n",
      "Epoch 10/10\n",
      "884/884 [==============================] - 13s 15ms/step - loss: 1.1144 - categorical_accuracy: 0.5902 - precision: 0.7768 - recall: 0.3895 - f1_score: 0.5810 - val_loss: 1.1193 - val_categorical_accuracy: 0.5846 - val_precision: 0.7662 - val_recall: 0.3885 - val_f1_score: 0.5815 - lr: 4.0657e-04\n",
      "Epoch 1/10\n",
      "884/884 [==============================] - 65s 73ms/step - loss: 2.9853 - categorical_accuracy: 0.2986 - precision: 0.3494 - recall: 0.0838 - f1_score: 0.2858 - val_loss: 1.8828 - val_categorical_accuracy: 0.2991 - val_precision: 0.6216 - val_recall: 0.0130 - val_f1_score: 0.2093 - lr: 0.0010\n",
      "Epoch 2/10\n",
      "884/884 [==============================] - 63s 72ms/step - loss: 1.8318 - categorical_accuracy: 0.3362 - precision: 0.6121 - recall: 0.0479 - f1_score: 0.3043 - val_loss: 1.9304 - val_categorical_accuracy: 0.2875 - val_precision: 0.6242 - val_recall: 0.0277 - val_f1_score: 0.1875 - lr: 9.0484e-04\n",
      "Epoch 3/10\n",
      "884/884 [==============================] - 62s 71ms/step - loss: 1.8251 - categorical_accuracy: 0.3415 - precision: 0.6218 - recall: 0.0494 - f1_score: 0.3063 - val_loss: 1.8760 - val_categorical_accuracy: 0.3113 - val_precision: 0.6364 - val_recall: 0.0178 - val_f1_score: 0.2236 - lr: 8.1873e-04\n",
      "Epoch 4/10\n",
      "884/884 [==============================] - 62s 70ms/step - loss: 1.8329 - categorical_accuracy: 0.3432 - precision: 0.6140 - recall: 0.0493 - f1_score: 0.3077 - val_loss: 1.8500 - val_categorical_accuracy: 0.3209 - val_precision: 0.6271 - val_recall: 0.0209 - val_f1_score: 0.2480 - lr: 7.4082e-04\n",
      "Epoch 5/10\n",
      "884/884 [==============================] - 61s 69ms/step - loss: 1.8211 - categorical_accuracy: 0.3440 - precision: 0.6215 - recall: 0.0508 - f1_score: 0.3077 - val_loss: 1.8179 - val_categorical_accuracy: 0.3398 - val_precision: 0.6280 - val_recall: 0.0368 - val_f1_score: 0.2864 - lr: 6.7032e-04\n",
      "Epoch 6/10\n",
      "884/884 [==============================] - 62s 70ms/step - loss: 1.8122 - categorical_accuracy: 0.3495 - precision: 0.6241 - recall: 0.0530 - f1_score: 0.3129 - val_loss: 1.8114 - val_categorical_accuracy: 0.3430 - val_precision: 0.6158 - val_recall: 0.0331 - val_f1_score: 0.2927 - lr: 6.0653e-04\n",
      "Epoch 7/10\n",
      "884/884 [==============================] - 62s 70ms/step - loss: 1.8038 - categorical_accuracy: 0.3481 - precision: 0.6196 - recall: 0.0533 - f1_score: 0.3122 - val_loss: 1.8025 - val_categorical_accuracy: 0.3438 - val_precision: 0.6131 - val_recall: 0.0345 - val_f1_score: 0.2926 - lr: 5.4881e-04\n",
      "Epoch 8/10\n",
      "884/884 [==============================] - 52s 59ms/step - loss: 1.8483 - categorical_accuracy: 0.3454 - precision: 0.5796 - recall: 0.0579 - f1_score: 0.3106 - val_loss: 1.8053 - val_categorical_accuracy: 0.3509 - val_precision: 0.6129 - val_recall: 0.0376 - val_f1_score: 0.3122 - lr: 4.9659e-04\n",
      "Epoch 9/10\n",
      "884/884 [==============================] - 53s 60ms/step - loss: 1.7809 - categorical_accuracy: 0.3536 - precision: 0.6238 - recall: 0.0566 - f1_score: 0.3172 - val_loss: 1.7767 - val_categorical_accuracy: 0.3472 - val_precision: 0.6134 - val_recall: 0.0337 - val_f1_score: 0.3038 - lr: 4.4933e-04\n",
      "Epoch 10/10\n",
      "884/884 [==============================] - 52s 59ms/step - loss: 1.7680 - categorical_accuracy: 0.3535 - precision: 0.6246 - recall: 0.0573 - f1_score: 0.3165 - val_loss: 1.7665 - val_categorical_accuracy: 0.3517 - val_precision: 0.6170 - val_recall: 0.0410 - val_f1_score: 0.3098 - lr: 4.0657e-04\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x717ff06c5950>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn.fit(\n",
    "    train_ds,\n",
    "    epochs=10,\n",
    "    validation_data=val_ds,\n",
    "    callbacks=[\n",
    "        f1_save_last_callbacks,\n",
    "        f1_early_stopping_callback,\n",
    "        f1_save_best_callbacks,\n",
    "        LearningRateScheduler(lr_scheduler),\n",
    "    ],\n",
    ")\n",
    "mlp.fit(\n",
    "    train_ds,\n",
    "    epochs=10,\n",
    "    validation_data=val_ds,\n",
    "    callbacks=[\n",
    "        f1_save_last_callbacks,\n",
    "        f1_early_stopping_callback,\n",
    "        f1_save_best_callbacks,\n",
    "        LearningRateScheduler(lr_scheduler),\n",
    "    ],\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
